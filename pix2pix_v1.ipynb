{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UVAYTXvGuewg"
   },
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21371,
     "status": "ok",
     "timestamp": 1611147616944,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "2ttQ-ZSF5CyV",
    "outputId": "02f6eaae-7554-4966-c343-8e6dcb4df50e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7185,
     "status": "ok",
     "timestamp": 1611147624139,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "vjc5y4EK5E4n"
   },
   "outputs": [],
   "source": [
    "src_zip = '/content/drive/MyDrive/Colab Notebooks/gan/pix2pix_faceseg/faceseg_clean.zip'\n",
    "cpy_zip = './' \n",
    "\n",
    "import zipfile\n",
    "with zipfile.ZipFile(src_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(cpy_zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6334,
     "status": "ok",
     "timestamp": 1611147624144,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "Z_1DStis5GvG",
    "outputId": "8b997d7e-bfb7-4718-f692-e40ffce2f0cc"
   },
   "outputs": [],
   "source": [
    "cd '/content/drive/MyDrive/Colab Notebooks/gan/pix2pix_faceseg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1366,
     "status": "ok",
     "timestamp": 1611147625526,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "4J534YIj4bQT",
    "outputId": "b8665188-cc3d-4af4-f58f-b16f9593806b"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5086,
     "status": "ok",
     "timestamp": 1611147634134,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "SUAiC3YK4fC1"
   },
   "outputs": [],
   "source": [
    "from models import *\n",
    "from datagen import *\n",
    "from utils import *\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1441,
     "status": "ok",
     "timestamp": 1611149465237,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "i0GqXoyc4fC2"
   },
   "outputs": [],
   "source": [
    "# train pix2pix models\n",
    "def train(d_model, g_model, gan_model, path_images, path_labels, n_epochs=100, batch_size=1, path_results='model_performance/', out_shape=(512,512,3)):\n",
    "    if not os.path.isdir(path_results):\n",
    "        os.mkdir(path_results)\n",
    "    \n",
    "    # determine the output square shape of the discriminator\n",
    "    n_patch = (d_model.output_shape[1],d_model.output_shape[2])\n",
    "\n",
    "    bat_per_epo = int(len(all_paths)/batch_size)\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    #n_steps = 5\n",
    "    print('Batch per epochs = ', bat_per_epo)\n",
    "    print('Total Steps = ', n_steps)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_steps):\n",
    "        # select a batch of real samples\n",
    "        X_realA, X_realB, y_real = next(my_datagen(path_images, path_labels, patch_shape = n_patch, batch_size=batch_size,out_shape=out_shape))\n",
    "        # generate a batch of fake samples\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "        \n",
    "       \n",
    "        # update discriminator for real samples\n",
    "        d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        # update discriminator for generated samples\n",
    "        d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        # update the generator\n",
    "        g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "        # summarize performance\n",
    "        print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
    "        # summarize model performance\n",
    "        if i%(bat_per_epo*4)==0 and i>1:\n",
    "            print('---------------------------------------')\n",
    "            print('Saving and evaluating model...')\n",
    "            g_model.save(path_results+'g_model.h5')\n",
    "            d_model.save(path_results+'d_model.h5')\n",
    "            gan_model.save(path_results+'gan_model.h5')\n",
    "            # select a sample of input images\n",
    "            X_realA, X_realB, _ = next(my_datagen(path_images, path_labels, patch_shape=n_patch, batch_size=3,out_shape=out_shape))\n",
    "            # generate a batch of fake samples\n",
    "            X_fakeB, _ = generate_fake_samples(g_model, X_realA, patch_shape=(1,1))\n",
    "            summarize_performance(path_results, i, g_model,  X_realA, X_realB, X_fakeB, n_samples=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3016,
     "status": "ok",
     "timestamp": 1611149484979,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "rndGQvz24fC4"
   },
   "outputs": [],
   "source": [
    "# path_images = 'maps_dataset_subset/train_images/'\n",
    "# path_labels = 'maps_dataset_subset/train_maps/'\n",
    "\n",
    "path_images = '/content/train_masks/'\n",
    "path_labels = '/content/train_images'\n",
    "\n",
    "all_paths = get_paths(path_images)\n",
    "\n",
    "image_shape = (512,512,3)\n",
    "\n",
    "d_model, g_model, gan_model = define_gan(image_shape)\n",
    "d_model.load_weights('model_performance/d_model.h5')\n",
    "g_model.load_weights('model_performance/g_model.h5')\n",
    "gan_model.load_weights('model_performance/gan_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH2pfjHG4fC5"
   },
   "outputs": [],
   "source": [
    "train(d_model, g_model, gan_model, path_images, path_labels,batch_size=4, out_shape=image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 943,
     "status": "ok",
     "timestamp": 1611152591641,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "_6X9wGxY4fC6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate samples and save as a plot and save the model\n",
    "def my_inference(path_results, step, g_model, X_realA, X_realB, X_fakeB, n_samples):\n",
    "\n",
    "    n_samples = len(X_realA)\n",
    "    # scale all pixels from [-1,1] to [0,1]\n",
    "    X_realA = (X_realA + 1) / 2.0\n",
    "    X_realB = (X_realB + 1) / 2.0\n",
    "    X_fakeB = (X_fakeB + 1) / 2.0\n",
    "    # plot real source images\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realA[i])\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_fakeB[i])\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(X_realB[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1158,
     "status": "ok",
     "timestamp": 1611153245038,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "hhk8qz6ScIDS"
   },
   "outputs": [],
   "source": [
    "n_patch = (d_model.output_shape[1],d_model.output_shape[2])\n",
    "X_realA, X_realB, _ = next(my_datagen(path_images, path_labels, patch_shape=n_patch, batch_size=5, out_shape=image_shape))\n",
    "X_fakeB, _ = generate_fake_samples(g_model, X_realA, patch_shape=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "executionInfo": {
     "elapsed": 3047,
     "status": "ok",
     "timestamp": 1611153247534,
     "user": {
      "displayName": "Waleed Raza",
      "photoUrl": "",
      "userId": "17515228258510558593"
     },
     "user_tz": -300
    },
    "id": "Jf2M_BhkcYli",
    "outputId": "9ee5374c-6cd9-4c0c-a965-62e95f42e2cf"
   },
   "outputs": [],
   "source": [
    "my_inference('xxx', 0, g_model,  X_realA, X_realB, X_fakeB, n_samples=len(X_realA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
